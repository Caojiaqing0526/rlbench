{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import algos\n",
    "import features\n",
    "import parametric\n",
    "import policy\n",
    "import chicken\n",
    "from agents import OffPolicyAgent, OnPolicyAgent\n",
    "from rlbench import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HordeAgent:\n",
    "    def __init__(self, algo, pol, phi, update_params=dict()):\n",
    "        self.algo = algo\n",
    "        self.pol = pol\n",
    "        if phi is None: \n",
    "            self.phi = lambda x: x \n",
    "        else: \n",
    "            self.phi = phi\n",
    "        # default parameter functions to use for updates\n",
    "        self.param_funcs = {k: parametric.to_parameter(v) \n",
    "                            for k, v in update_params.items()}\n",
    "        \n",
    "    def update(self, s, a, r, sp, **params):\n",
    "        # determine the state dependent update params\n",
    "        update_params = {k: v(s) for k, v in self.param_funcs.items()}\n",
    "        # compute the action selection probability ratio\n",
    "        update_params['rho'] = self.pol.prob(s, a)\n",
    "        update_params.update(**params)\n",
    "        # get the arguments to pass to the function \n",
    "        args = [update_params[k] for k in self.algo.update_params]\n",
    "        \n",
    "        # function approximation\n",
    "        x = self.phi(s)\n",
    "        xp = self.phi(sp)\n",
    "        \n",
    "        return self.algo.update(x, r, xp, *args)\n",
    "    \n",
    "    @property\n",
    "    def theta(self):\n",
    "        return self.algo.theta\n",
    "    \n",
    "    def get_values(self, states):\n",
    "        \"\"\"Compute the values for each of the given states.\"\"\"\n",
    "        theta = self.theta\n",
    "        return {s: np.dot(theta, self.phi(s)) for s in states}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_many(agent_lst, behavior, env, max_steps):\n",
    "    steps = []\n",
    "    error_dct = {}\n",
    "    t = 0\n",
    "    \n",
    "    # reset the environment and get initial state\n",
    "    env.reset()\n",
    "    s = env.state\n",
    "    while not env.is_terminal() and t < max_steps:\n",
    "        a = behavior.choose(s, env.actions)\n",
    "        r, sp = env.do(a)\n",
    "        \n",
    "        # update the agents\n",
    "        for agent in agent_lst:\n",
    "            delta = agent.update(s, a, r, sp)\n",
    "        \n",
    "        # record the transition\n",
    "        ret.append((s, a, r, sp))\n",
    "        \n",
    "        # prepare for next iteration\n",
    "        t += 1\n",
    "        s = sp\n",
    "    \n",
    "    # return information about the run\n",
    "    ret = {}\n",
    "    return ret  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_agents(algo_lst, target, phi, update_params):\n",
    "    \"\"\"A quick function for making HordeAgent objects from a list \n",
    "    of algorithm classes. Somewhat brittle.\n",
    "    \"\"\"\n",
    "    ret = []\n",
    "    for cls in algo_lst:\n",
    "        algo = cls(phi.length) \n",
    "        params = {k: v for k, v in update_params.items() if k in algo.update_params}\n",
    "        container = HordeAgent(algo, target, phi, params)\n",
    "        ret.append(container)\n",
    "    return ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the experiment\n",
    "num_states = 8\n",
    "\n",
    "# set up environment\n",
    "env = chicken.Chicken(num_states)\n",
    "\n",
    "# set up algorithm parameters\n",
    "update_params = {\n",
    "    'alpha': 0.02,\n",
    "    'beta': 0.002,\n",
    "    'gm': 0.9,\n",
    "    'gm_p': 0.9,\n",
    "    'lm': 0.0,\n",
    "    'lm_p': 0.0,\n",
    "    'interest': 1.0,\n",
    "}\n",
    "\n",
    "# Define the target policy\n",
    "pol_pi = policy.FixedPolicy({s: {0: 1} for s in env.states})\n",
    "\n",
    "# set feature mapping\n",
    "# phi = features.RandomBinary(num_features, num_features // 2, random_seed=101011)\n",
    "num_features = 8\n",
    "phi = features.Int2Unary(num_states)\n",
    "\n",
    "agent_lst = make_agents([algos.TD, algos.ETD], pol_pi, phi, update_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the experiment\n",
    "max_steps = 500\n",
    "\n",
    "# Define the behavior policy\n",
    "pol_mu = policy.FixedPolicy({s: {0: 1} if s < 4 else {0: 0.5, 1: 0.5} for s in env.states})\n",
    "\n",
    "data = run_horde(agent_lst, pol_mu, env, max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up algorithm parameters\n",
    "update_params = {\n",
    "    'alpha': 0.02,\n",
    "    'beta': 0.002,\n",
    "    'gm': 0.9,\n",
    "    'gm_p': 0.9,\n",
    "    'lm': 0.0,\n",
    "    'lm_p': 0.0,\n",
    "    'interest': 1.0,\n",
    "}\n",
    "\n",
    "# Define the target policy\n",
    "pol_pi = policy.FixedPolicy({s: {0: 1} for s in env.states})\n",
    "# Define the behavior policy\n",
    "pol_mu = policy.FixedPolicy({s: {0: 1} if s < 4 else {0: 0.5, 1: 0.5} for s in env.states})\n",
    "\n",
    "\n",
    "# Run all available algorithms \n",
    "max_steps = 50000\n",
    "for name, alg in algos.algo_registry.items():    \n",
    "    # Set up the agent, run the experiment, get state-values\n",
    "    agent = OffPolicyAgent(alg(phi.length), pol_pi, pol_mu, phi, update_params)\n",
    "    mse_lst = run_errors(agent, env, max_steps, mse_values)\n",
    "    mspbe_lst = run_errors(agent, env, max_steps, mspbe_values)\n",
    "\n",
    "    # Plot the errors\n",
    "    xdata = np.arange(max_steps)\n",
    "    plt.plot(xdata, mse_lst)\n",
    "    plt.plot(xdata, mspbe_lst)\n",
    "#     plt.plot(xdata, np.log(mse_lst))\n",
    "#     plt.plot(xdata, np.log(mspbe_lst))\n",
    "    \n",
    "    # Format and label the graph\n",
    "    plt.ylim(0, 2)\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.ylabel('Error')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
